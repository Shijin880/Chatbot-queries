{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Problem statement 5. Document-based Question Answering System (GenAI)\n",
        "Objective:\n",
        "Allow users to upload documents (PDFs, Word files) and ask questions based on the content.\n",
        "Tech Stack:\n",
        "LangChain, OpenAI API (GPT-4), ChromaDB or FAISS, Streamlit\n",
        "Description:\n",
        "This is a Generative AI app that uses LLMs and vector search to provide intelligent answers from within a document. Upon upload, the text is chunked and embedded using OpenAI embeddings. A user query is also embedded, and the most similar chunk(s) are passed to the LLM to generate an answer with context.\n",
        "Key Features:\n",
        "•\tFile upload (PDF/Doc)\n",
        "•\tChunking + vector embedding\n",
        "•\tContext-aware LLM answer generation\n",
        "•\tSimple and professional UI\n",
        "Use Case:\n",
        "Useful in legal firms, educational platforms, and knowledge management tools.\n"
      ],
      "metadata": {
        "id": "M1E97KfGNPVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective :- to answer all queries based on scientific theories ,refering journal scientific theory for education platform"
      ],
      "metadata": {
        "id": "ky7i-Wx_WdXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade boltiotai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT8LVPfZmxbP",
        "outputId": "348fc26f-1c15-49dd-cd87-de70e159048b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boltiotai\n",
            "  Downloading boltiotai-0.0.3-py3-none-any.whl.metadata (413 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from boltiotai) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->boltiotai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->boltiotai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->boltiotai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->boltiotai) (2025.6.15)\n",
            "Downloading boltiotai-0.0.3-py3-none-any.whl (5.4 kB)\n",
            "Installing collected packages: boltiotai\n",
            "Successfully installed boltiotai-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from boltiotai import openai"
      ],
      "metadata": {
        "id": "xrYFcpI_m04F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fUVWUreDeqPZ"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install openai > /dev/null 2>&1 || echo \"Error: Installation failed\"\n",
        "!pip install langchain langchain_community > /dev/null 2>&1 || echo \"Error: Installation failed\"\n",
        "!pip install --upgrade --quiet langchain langchainhub\n",
        "!pip install pymupdf pypdf > /dev/null 2>&1 || echo \"Error: Installation failed\"\n",
        "!pip install faiss-cpu > /dev/null 2>&1 || echo \"Error: Installation failed\"\n",
        "!pip install tiktoken > /dev/null 2>&1 || echo \"Error: Installation failed\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Filter out any warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "bn4wF-FSevhT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def display_response(response, width=80):\n",
        "    \"\"\"\n",
        "    Display the AI response in a readable format, preserving original line breaks.\n",
        "\n",
        "    Args:\n",
        "    response (str): The text response from the AI.\n",
        "    width (int): The maximum width of each line before wrapping.\n",
        "    \"\"\"\n",
        "    # Split the response into lines\n",
        "    lines = response.split('\\n')\n",
        "\n",
        "    # Wrap each line individually\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip() == '':\n",
        "            wrapped_lines.append('')\n",
        "        else:\n",
        "            wrapped_lines.extend(textwrap.wrap(line, width=width))\n",
        "\n",
        "    # Join the wrapped lines\n",
        "    wrapped_text = '\\n'.join(wrapped_lines)\n",
        "\n",
        "    # Add markdown formatting\n",
        "    formatted_text = f\"```\\n{wrapped_text}\\n```\"\n",
        "    #formatted_text = f\"\\n{wrapped_text}\\n\"\n",
        "\n",
        "    # Display as markdown\n",
        "    display(Markdown(formatted_text))\n",
        "\n",
        "\n",
        "def display_input_output(input, output):\n",
        "  print(\"Prompt:\\n\")\n",
        "  display_response(input)\n",
        "  print(\"\\nResponse:\\n\")\n",
        "  display_response(output)"
      ],
      "metadata": {
        "id": "er7BZc7YexQd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "import textwrap\n",
        "from IPython.display import display, Markdown\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "\n",
        "# Filter out any warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Securely get the API key. The key should be set in Colab's Secrets.\n",
        "import openai\n",
        "\n",
        "\n",
        "# Set up OpenAI API key securely\n",
        "from google.colab import userdata\n",
        "\n",
        "# Securely get the API key\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Ensure the API key is set\n",
        "if OPENAI_API_KEY is None:\n",
        "    raise ValueError(\"Please set the OPENAI_API_KEY in Colab's Secrets (under Tools > Settings > Secrets)\")\n",
        "\n",
        "# Set the API key for OpenAI\n",
        "openai_api_key = 'AIzaSyCpN7OdUyp46eTX5SkCIY606RxgI1GlQbY'\n",
        "\n",
        "openai_api_key = OPENAI_API_KEY\n",
        "\n",
        "def display_response(response, width=80):\n",
        "    \"\"\"\n",
        "    Display the AI response in a readable format, preserving original line breaks.\n",
        "    \"\"\"\n",
        "    lines = response.split('\\n')\n",
        "    wrapped_lines = []\n",
        "    for line in lines:\n",
        "        if line.strip() == '':\n",
        "            wrapped_lines.append('')\n",
        "        else:\n",
        "            wrapped_lines.extend(textwrap.wrap(line, width=width))\n",
        "    display(Markdown(\"\\n\".join(wrapped_lines)))"
      ],
      "metadata": {
        "id": "gF9WgU0he3kY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "\n",
        "from langchain.document_loaders import PyMuPDFLoader  # PDF loader\n",
        "from langchain.document_loaders import PyPDFLoader  # PDF loader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "XPTrGhydlwid"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename from the uploaded dictionary\n",
        "if uploaded:\n",
        "  file_name = list(uploaded.keys())[0]\n",
        "  loader = PyMuPDFLoader(file_name) # Using PyMuPDFLoader which is already imported\n",
        "  documents = loader.load()\n",
        "\n",
        "  print(f\"Loaded {len(documents)} pages from {file_name}\")\n",
        "  if documents:\n",
        "    print(\"First page content preview:\")\n",
        "    print(documents[0].page_content[:500]) # Print the first 500 characters of the first page\n",
        "else:\n",
        "  print(\"No file was uploaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "yMEgayXwSwp4",
        "outputId": "26f01bc0-7a15-43f8-9266-49c581a26dc7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6c19f367-67a4-4a41-86ed-96227b2c4394\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6c19f367-67a4-4a41-86ed-96227b2c4394\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Scientific_Theories.pdf to Scientific_Theories (1).pdf\n",
            "Loaded 33 pages from Scientific_Theories (1).pdf\n",
            "First page content preview:\n",
            "See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/282216625\n",
            "Scientiﬁc Theories\n",
            "Article · February 2015\n",
            "CITATIONS\n",
            "8\n",
            "READS\n",
            "8,681\n",
            "1 author:\n",
            "Hans Halvorson\n",
            "Princeton University\n",
            "89 PUBLICATIONS   2,434 CITATIONS   \n",
            "SEE PROFILE\n",
            "All content following this page was uploaded by Hans Halvorson on 04 December 2020.\n",
            "The user has requested enhancement of the downloaded file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if documents:\n",
        "  display_response(documents[0].page_content)\n",
        "else:\n",
        "  print(\"No documents loaded.\")"
      ],
      "metadata": {
        "id": "_qyQC-00tNsf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "0500a18f-7560-4920-cead-b4ff49e73c56"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "See discussions, stats, and author profiles for this publication at:\nhttps://www.researchgate.net/publication/282216625\nScientiﬁc Theories\nArticle · February 2015\nCITATIONS\n8\nREADS\n8,681\n1 author:\nHans Halvorson\nPrinceton University\n89 PUBLICATIONS   2,434 CITATIONS   \nSEE PROFILE\nAll content following this page was uploaded by Hans Halvorson on 04 December\n2020.\nThe user has requested enhancement of the downloaded file."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sXsrqD0WeM5",
        "outputId": "5309456b-ef89-4589-c578-8c8100307fb3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# Pass the API key using the correct parameter name 'openai_api_key'\n",
        "# Use the OPENAI_API_KEY retrieved securely from Colab secrets\n",
        "embeddings = OpenAIEmbeddings(openai_api_key='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')\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "\n",
        "# Now split the documents loaded in a previous cell\n",
        "split_documents = text_splitter.split_documents(documents)\n",
        "vector_store = FAISS.from_documents(split_documents, embeddings)"
      ],
      "metadata": {
        "id": "EEOgtP1pmWwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75896f40-5048-4434-81b1-70c5fad37a80"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-2853079527.py:7: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings(openai_api_key='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')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a retriever\n",
        "retriever = vector_store.as_retriever()"
      ],
      "metadata": {
        "id": "E4ZDxrQWnGzO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1,  openai_api_key = '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') # We are using gpt-4o-mini"
      ],
      "metadata": {
        "id": "PbHLdORNnT_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b45de35-bb0c-4eb2-ca88-765b4cfd3bd4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-15-1368203650.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1,  openai_api_key = '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') # We are using gpt-4o-mini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RAG system\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",  # Use \"stuff\" for a simple RAG setup, other chain_type are 'map_reduce', 'refine'\n",
        "    retriever=retriever\n",
        ")\n"
      ],
      "metadata": {
        "id": "4Dva1bTUnKEN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = vector_store.similarity_search(query, k=3)"
      ],
      "metadata": {
        "id": "LMZ9ELWesCcy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "id": "iSQeOqcsEqxp",
        "outputId": "01ebe318-ee94-47b1-e71f-a516d74da06a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].metadata\n"
      ],
      "metadata": {
        "id": "aP6hxjr1sJvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0f28eb-d282-4d85-b6bf-fdf6397c619e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'producer': 'pdfTeX-1.40.15',\n",
              " 'creator': 'TeX',\n",
              " 'creationdate': '2015-02-27T09:51:34-05:00',\n",
              " 'source': 'Scientific_Theories (1).pdf',\n",
              " 'file_path': 'Scientific_Theories (1).pdf',\n",
              " 'total_pages': 33,\n",
              " 'format': 'PDF 1.5',\n",
              " 'title': '',\n",
              " 'author': '',\n",
              " 'subject': '',\n",
              " 'keywords': '',\n",
              " 'moddate': '2015-02-27T09:51:34-05:00',\n",
              " 'trapped': '',\n",
              " 'modDate': \"D:20150227095134-05'00'\",\n",
              " 'creationDate': \"D:20150227095134-05'00'\",\n",
              " 'page': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = input(\"Enter your query: \")\n",
        "display_response(rag_chain.run(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "d4N_nAW9ALz7",
        "outputId": "8f313bed-cd17-4950-b0d0-54310fb7a537"
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query: what is sematic views of theory\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The semantic view of theories is a philosophical approach that defines\nscientific theories as collections of models rather than as sets of sentences or\npropositions. This perspective emphasizes the role of mathematical structures\nand model theory in understanding scientific theories. According to the semantic\nview, a scientific theory consists of a class of L-structures (interpretations\nof a language L) that represent various aspects of the world.\n\nProponents of the semantic view argue that it allows for a more flexible and\ninclusive understanding of theories, as it does not rely solely on language-\ndependent formulations. Instead, it focuses on the relationships and\nsimilarities between models and the intended domain of study. The semantic view\nalso distinguishes between a theoretical definition (the abstract mathematical\nobject) and a theoretical hypothesis (the claim that some part of the world can\nbe represented by that object)."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PnzqhyH2s-UC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}